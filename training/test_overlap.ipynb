{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","mount_file_id":"1vtjwez7wxt0mrap2X2H6IPSF5AbOyaeO","authorship_tag":"ABX9TyOQjETfFbNxzAcFnJaVTTKM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"novewIwUSACx","executionInfo":{"status":"ok","timestamp":1689017851289,"user_tz":-330,"elapsed":76467,"user":{"displayName":"Neetha P U","userId":"14316991184318355213"}},"outputId":"95c5302d-1753-407e-ed9c-6bd06a53a040"},"outputs":[{"output_type":"stream","name":"stdout","text":["616/616 [==============================] - 13s 8ms/step - loss: 1.0531e-08 - sparse_categorical_accuracy: 1.0000\n","616/616 [==============================] - 4s 7ms/step\n","Classification Report :\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00     14799\n","           1       1.00      1.00      1.00      3477\n","           2       1.00      1.00      1.00      1421\n","\n","    accuracy                           1.00     19697\n","   macro avg       1.00      1.00      1.00     19697\n","weighted avg       1.00      1.00      1.00     19697\n","\n","Mode:  MM_SA_BA\n","Batch size:   1024\n","Learning rate:  0.001\n","Epochs:   50\n","Test Accuracy: 1.0 \n","-------------------------------------------------------\n","{1.0: ('MM_SA_BA', 1.0, 1024, 0.001, 50)}\n","-------------------------------------------------------\n","Highest accuracy of: 1.0 with parameters: ('MM_SA_BA', 1.0, 1024, 0.001, 50)\n"]}],"source":["import os\n","import random\n","import pickle\n","import gc, numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.utils import compute_class_weight\n","import tensorflow as tf\n","from keras.models import Model\n","from keras import backend as K\n","from keras.layers import Input, Dense, Dropout,Flatten, BatchNormalization, Conv2D, MultiHeadAttention, concatenate\n","from sklearn.metrics import classification_report\n","from tensorflow.keras.optimizers import Adam\n","from keras.models import Sequential,load_model\n","from tensorflow.keras.utils import to_categorical\n","import seaborn as sns\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import precision_recall_curve\n","\n","\n","config = tf.compat.v1.ConfigProto()\n","config.gpu_options.allow_growth=True\n","sess = tf.compat.v1.Session(config=config)\n","\n","\n","def make_img(t_img):\n","    img = pd.read_pickle(t_img)\n","    img_l = []\n","    for i in range(len(img)):\n","        img_l.append(img.values[i][1])\n","    return np.array(img_l)\n","\n","\n","def calc_confusion_matrix(result, test_label,mode, learning_rate, batch_size, epochs):\n","    test_label = to_categorical(test_label,3)\n","    true_label= np.argmax(test_label, axis =1)\n","    predicted_label= np.argmax(result, axis =1)\n","\n","    n_classes = 3\n","    precision = dict()\n","    recall = dict()\n","    thres = dict()\n","    for i in range(n_classes):\n","        precision[i], recall[i], thres[i] = precision_recall_curve(test_label[:, i],\n","                                                            result[:, i])\n","\n","\n","    print (\"Classification Report :\")\n","    print (classification_report(true_label, predicted_label))\n","    cr = classification_report(true_label, predicted_label, output_dict=True)\n","    return cr, precision, recall, thres\n","\n","\n","def test_model(mode, batch_size, epochs, learning_rate,):\n","    #?clinical\n","    test_clinical= pd.read_pickle(\"/content/drive/MyDrive/preprocessing_overlap/dataset/X_test_clinical.pkl\").fillna(0).replace(r'[^0-9]',0,regex=True).astype(\"float32\").values\n","\n","    #?Genetic\n","    test_snp = pd.read_pickle(\"/content/drive/MyDrive/preprocessing_overlap/dataset/X_test_snp.pkl\").fillna(0).replace(r'[^0-9]',0,regex=True).astype(\"float32\").values\n","\n","    #?MRI image\n","    test_img= make_img(\"/content/drive/MyDrive/preprocessing_overlap/dataset/X_test_img.pkl\")\n","\n","    test_img= test_img.reshape(-1,72,72,3)\n","    test_img= np.asarray(test_img).astype('float32')\n","\n","    #?overlap\n","    test_label= pd.read_pickle(\"/content/drive/MyDrive/preprocessing_overlap/dataset/y_test.pkl\").values.astype(\"float32\").flatten()\n","\n","\n","    model =load_model(\"/content/drive/MyDrive/preprocessing_overlap/dataset/train_all.hdf5\")\n","    score = model.evaluate([test_clinical, test_snp, test_img], test_label)\n","\n","    acc = score[1]\n","    test_predictions = model.predict([test_clinical, test_snp, test_img])\n","    cr, precision_d, recall_d, thres = calc_confusion_matrix(test_predictions, test_label, mode, learning_rate, batch_size, epochs)\n","\n","    # release gpu memory #\n","    K.clear_session()\n","    del model\n","    gc.collect()\n","\n","\n","    print ('Mode: ', mode)\n","    print ('Batch size:  ', batch_size)\n","    print ('Learning rate: ', learning_rate)\n","    print ('Epochs:  ', epochs)\n","    print ('Test Accuracy: {} '.format(acc))\n","    print ('-'*55)\n","    return acc, batch_size, learning_rate, epochs\n","\n","\n","\n","if __name__==\"__main__\":\n","    m_a={}\n","    acc, bs_, lr_, e_ = test_model('MM_SA_BA', 1024, 50, 0.001)\n","    m_a[acc] = ('MM_SA_BA', acc, bs_, lr_, e_)\n","    print(m_a)\n","    print ('-'*55)\n","    max_acc = max(m_a, key=float)\n","    print(\"Highest accuracy of: \" + str(max_acc) + \" with parameters: \" + str(m_a[max_acc]))\n"]}]}